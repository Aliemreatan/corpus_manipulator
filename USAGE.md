# Corpus Data Manipulator - KullanÄ±m KÄ±lavuzu

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### 1. Temel Kurulum
```bash
# Proje dizinine gidin
cd corpus_manipulator

# Gereksinimleri yÃ¼kleyin (opsiyonel, temel iÅŸlevsellik iÃ§in gerekli deÄŸil)
pip install -r requirements.txt

# Basit demo Ã§alÄ±ÅŸtÄ±rÄ±n (gÃ¼venli)
py demo_fixed.py
```

### 2. Ä°lk KullanÄ±m

#### A) Python'da KullanÄ±m
```python
import sys
sys.path.append('.')

# Temel bileÅŸenler
from database.schema import CorpusDatabase
from nlp.turkish_processor import TurkishNLPProcessor
from ingestion.corpus_ingestor import CorpusIngestor
from query.corpus_query import CorpusQuery

# VeritabanÄ± oluÅŸtur
db = CorpusDatabase("my_corpus.db")
db.connect()
db.create_schema()

# NLP processor oluÅŸtur
nlp = TurkishNLPProcessor(backend='simple')

# Corpus ingestor oluÅŸtur
ingestor = CorpusIngestor("my_corpus.db", nlp_backend='simple')

# Metin dosyalarÄ±nÄ± iÃ§eri aktar
ingestor.ingest_directory("./sample_turkish_corpus")

# Sorgu yap
query = CorpusQuery("my_corpus.db")
stats = query.get_processing_stats()

print(f"Toplam token: {stats['database_stats']['total_tokens']}")

# Temizlik
ingestor.close()
query.close()
db.close()
```

#### B) Basit Metin Ä°ÅŸleme
```python
from nlp.turkish_processor import TurkishNLPProcessor

# NLP processor
nlp = TurkishNLPProcessor(backend='simple')

# Metin iÅŸle
text = "Bu bir test cÃ¼mlesidir. TÃ¼rkÃ§e dil iÅŸleme iÃ§in kullanÄ±lÄ±r."
tokens = nlp.process_text(text)

print(f"Token sayÄ±sÄ±: {len(tokens)}")
for token in tokens[:5]:
    print(f"{token['form']} -> norm: {token['norm']}")
```

## ğŸ“Š Mevcut Ã–zellikler

### âœ… Ã‡alÄ±ÅŸan Ã–zellikler
- **VeritabanÄ±**: SQLite + FTS5 tabanlÄ± depolama
- **Tokenizasyon**: Basit regex-based tokenizasyon
- **Frekans Analizi**: Kelime frekans listeleri
- **KWIC**: BaÄŸlamlÄ± arama (temel seviye)
- **Collocation**: PMI, log-likelihood hesaplamalarÄ±
- **Batch Processing**: BÃ¼yÃ¼k dosya desteÄŸi
- **Hata ToleransÄ±**: Fallback sistemleri

### âš ï¸ KÄ±sÄ±tlÄ± Ã–zellikler (spaCy/Stanza gerekli)
- **POS Tagging**: spaCy/Stanza kuruluysa aktif
- **Lemma**: spaCy/Stanza kuruluysa aktif  
- **Dependency Parsing**: spaCy/Stanza kuruluysa aktif
- **GeliÅŸmiÅŸ Morphology**: spaCy/Stanza kuruluysa aktif

## ğŸ”§ Kurulum SeÃ§enekleri

### SeÃ§enek 1: Temel Sistem (Ã–nerilen)
```bash
# Sadece temel Ã¶zellikler
pip install numpy pandas regex tqdm

# Demo Ã§alÄ±ÅŸtÄ±r
py demo_fixed.py
```

### SeÃ§enek 2: spaCy ile (Ã–nerilen)
```bash
# Python 3.13 veya altÄ± kullanÄ±n (Python 3.14'te sorun var)
pip install spacy==3.7.4
python -m spacy download tr_core_news_sm

# Test
python -c "import spacy; nlp = spacy.load('tr_core_news_sm'); print('spaCy Ã§alÄ±ÅŸÄ±yor')"
```

### SeÃ§enek 3: Stanza ile
```bash
# Stanza kurulum
pip install stanza
python -m stanza.download('tr')

# Test
python -c "import stanza; nlp = stanza.Pipeline('tr'); print('Stanza Ã§alÄ±ÅŸÄ±yor')"
```

### SeÃ§enek 4: BERT Modeli ile
```bash
# PyTorch ve Transformers
pip install torch transformers

# Kendi BERT modelinizi ekleyin
# models/ klasÃ¶rÃ¼ne koyun
```

## ğŸ¯ Ã–rnek KullanÄ±m SenaryolarÄ±

### Senaryo 1: Akademik AraÅŸtÄ±rma
```python
# YÃ¼ksek doÄŸruluk gerektiren Ã§alÄ±ÅŸmalar
from corpus_manipulator.query import CorpusQuery

query = CorpusQuery("research_corpus.db")

# Frekans analizi
frequencies = query.frequency_list(word_type='lemma', limit=100)

# Collocation analizi
collocations = query.collocation_analysis("demokrasi", measure='pmi')

# KWIC arama
kwic = query.kwic_concordance("anayasa", window_size=5)

print(f"En sÄ±k kelimeler: {frequencies[:10]}")
print(f"Anayasa collocations: {collocations[:5]}")
```

### Senaryo 2: Production Sistem
```python
# HÄ±zlÄ± ve gÃ¼venilir sistem
from ingestion.corpus_ingestor import CorpusIngestor

# BÃ¼yÃ¼k corpus iÅŸleme
ingestor = CorpusIngestor("production.db", nlp_backend='simple')

# Batch processing
stats = ingestor.ingest_directory(
    "./large_corpus", 
    file_pattern="*.txt",
    max_files=1000,
    batch_size=5000
)

print(f"Ä°ÅŸlenen: {stats['documents_processed']} dosya")
print(f"Toplam: {stats['tokens_processed']} token")
```

### Senaryo 3: Kelime Analizi
```python
from query.corpus_query import CorpusQuery

query = CorpusQuery("analysis.db")

# Word sketch
sketch = query.word_sketch("ev")

print("Ev kelimesi iÃ§in dependency relations:")
for relation, words in sketch.items():
    print(f"  {relation}: {len(words)} baÄŸlantÄ±")
    
# Belirli relation
amod_relations = query.word_sketch("ev", relation_type="amod")
print(f"Adjectival modifiers: {amod_relations}")
```

## ğŸ› ï¸ Sorun Giderme

### YaygÄ±n Hatalar

#### 1. Python 3.14 spaCy sorunu
```bash
# Ã‡Ã¶zÃ¼m: Python 3.13 veya altÄ±nÄ± kullanÄ±n
# Veya simple backend kullanÄ±n

from nlp.turkish_processor import TurkishNLPProcessor
nlp = TurkishNLPProcessor(backend='simple')
```

#### 2. Import hatalarÄ±
```bash
# Ã‡Ã¶zÃ¼m: PYTHONPATH ekleyin
export PYTHONPATH="${PYTHONPATH}:$(pwd)"

# Veya sys.path kullanÄ±n
import sys
sys.path.append('.')
```

#### 3. Encoding hatalarÄ±
```python
# TÃ¼rkÃ§e karakterler iÃ§in UTF-8 kullanÄ±n
with open('file.txt', 'r', encoding='utf-8') as f:
    text = f.read()
```

#### 4. Bellek sorunlarÄ±
```python
# BÃ¼yÃ¼k dosyalar iÃ§in batch size dÃ¼ÅŸÃ¼rÃ¼n
ingestor.ingest_directory("./corpus", batch_size=1000)

# Veya dosyalarÄ± tek tek iÅŸleyin
for file_path in Path("./corpus").glob("*.txt"):
    ingestor.ingest_file(file_path)
```

## ğŸ“ˆ Performans Optimizasyonu

### HÄ±zlÄ± Ä°ÅŸleme
```python
# Basit backend kullanÄ±n
nlp = TurkishNLPProcessor(backend='simple')

# Batch processing
ingestor = CorpusIngestor("fast.db", nlp_backend='simple')
stats = ingestor.ingest_directory("./corpus", batch_size=10000)
```

### YÃ¼ksek DoÄŸruluk
```python
# spaCy kullanÄ±n (Python 3.13'te)
nlp = TurkishNLPProcessor(backend='spacy', model_name='tr_core_news_lg')

# Veya BERT modeli
from nlp.custom_bert_processor import create_custom_bert_processor
bert = create_custom_bert_processor("./my_bert_model")
```

## ğŸ“š Ek Kaynaklar

### Dosya YapÄ±sÄ±
```
corpus_manipulator/
â”œâ”€â”€ demo_fixed.py           # Ã‡alÄ±ÅŸan demo (gÃ¼venli)
â”œâ”€â”€ demo.py                # Ana demo (spaCy gerekli)
â”œâ”€â”€ README.md              # KapsamlÄ± dokÃ¼mantasyon
â”œâ”€â”€ database/              # VeritabanÄ± modÃ¼lleri
â”œâ”€â”€ nlp/                   # NLP iÅŸleme
â”œâ”€â”€ ingestion/             # Corpus import
â”œâ”€â”€ query/                 # Sorgu ve analiz
â””â”€â”€ docs/                  # DokÃ¼mantasyon
```

### API ReferansÄ±
- `CorpusDatabase`: VeritabanÄ± yÃ¶netimi
- `TurkishNLPProcessor`: NLP iÅŸleme
- `CorpusIngestor`: Corpus import
- `CorpusQuery`: Sorgu ve analiz
- `CustomBERTProcessor`: BERT model desteÄŸi

### Test Verileri
- `sample_turkish_corpus/`: Demo metinler
- `demo_simple.db`: Demo veritabanÄ±

## ğŸ’¡ Ä°puÃ§larÄ±

1. **BaÅŸlangÄ±Ã§ iÃ§in**: `demo_fixed.py` Ã§alÄ±ÅŸtÄ±rÄ±n
2. **spaCy kurulumu**: Python 3.13 kullanÄ±n
3. **BÃ¼yÃ¼k corpuslar**: Batch size optimize edin
4. **Hata durumunda**: Simple backend fallback
5. **BERT modeli**: Kendi fine-tuned modelinizi kullanÄ±n

**Sistem production-ready ve tÃ¼m temel Ã¶zellikler Ã§alÄ±ÅŸÄ±yor!**